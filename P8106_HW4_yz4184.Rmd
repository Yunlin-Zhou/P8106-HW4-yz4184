---
title: "P8106_HW4_yz4184"
author: "Yunlin Zhou"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

\newpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(tidyverse)
library(ISLR)
library(caret)
library(rpart)
library(rpart.plot)
library(party)
library(partykit)
library(randomForest)
library(ranger)
library(gbm)
library(pdp)
library(pROC)
```

# Problem 1

```{r, message = FALSE, results='hide', warning=FALSE}
# Import and clean the data
college_df = read.csv("./College.csv")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  relocate("outstate")%>%
  select(-college)

# Partition data into training/test sets
set.seed(1)
college_train = createDataPartition(y = college_df$outstate,
                                    p =0.8,
                                    list = FALSE)
train_df = college_df[college_train,]
test_df = college_df[-college_train,]
```

## Part a

### Build a regression tree on the training data to predict the response.

```{r}
ctrl <- trainControl(method = "cv")

set.seed(1)
tree1 <- train(outstate ~ .,
                  train_df, 
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                   trControl = ctrl)
tree1$bestTune
ggplot(tree1, highlight = TRUE)
```

In the pruned tree regression model, the tune parameter cp is `r tree1$bestTune`.


###  Create a plot of the tree.

```{r}
rpart.plot(tree1$finalModel)
```

\newpage

## Part b

### Perform random forest on the training data.

```{r}
set.seed(1)
rf.grid <- expand.grid(mtry = 1:16,
                       splitrule = "variance",
                       min.node.size = 1:6)

rf1 <- train(outstate ~ .,
             train_df,
             method = "ranger",
             tuneGrid = rf.grid,
             trControl = ctrl)

ggplot(rf1, highlight = TRUE)

rf1$bestTune
```

In this random forest model, the best model is with minimum node size `r rf1$bestTune[[3]]` and `r rf1$bestTune[[1]]` selected predictors.

### Report the variable importance.

```{r}
set.seed(1)
rf1.final.per <- ranger(outstate ~ . , 
                        train_df,
                        mtry = rf1$bestTune[[1]], 
                        splitrule = "variance",
                        min.node.size = rf1$bestTune[[3]],
                        importance = "permutation",
                        scale.permutation.importance = TRUE) 

barplot(sort(ranger::importance(rf1.final.per), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan","blue"))(16))
```

Using the permutation method, the most important predictors are expend and room_board.

### Report the test error.

```{r}
pred.rf <- predict(rf1, newdata = test_df)
te_rf = RMSE(pred.rf, test_df$outstate)
te_rf 
```

The test error is `r te_rf`.

\newpage

## Part c

### Perform boosting on the training data.

```{r}
gbm.grid <- expand.grid(n.trees = c(2000,3000,4000,5000),
                        interaction.depth = 1:5,
                        shrinkage = c(0.001,0.003,0.005),
                        n.minobsinnode = c(1,10))
set.seed(1)
gbm1 <- train(outstate ~ . ,
              train_df,
                 method = "gbm",
                 tuneGrid = gbm.grid,
                 trControl = ctrl,
                 verbose = FALSE)

gbm1$bestTune

ggplot(gbm1, highlight = TRUE)
```


### Report the variable importance.

```{r}
summary(gbm1$finalModel, las = 2, cBars = 16, cex.names = 0.6)
```

The most important predictors are expend and room_board.

### Report the test error.

```{r}
pred.gbm <- predict(gbm1, newdata = test_df)
te_gbm = RMSE(pred.gbm, test_df$outstate)
te_gbm
```

The test error is `r te_gbm`.

\newpage

# Queation 2

```{r, message = FALSE, results='hide', warning=FALSE}
# Import and clean the data
data(OJ)
oj_df= 
  OJ %>% 
  na.omit() %>% 
  janitor::clean_names() 

# Partition data into training/test sets
set.seed(2)
oj_train = createDataPartition(y = oj_df$purchase,
                                p = 700/1070,
                                    list = FALSE)
train_oj = oj_df[oj_train,]
test_oj = oj_df[-oj_train,]
```

## Part a

### Build a classification tree using the training data

```{r}
set.seed(2)
tree2 <- rpart(formula = purchase ~ . , 
               data =  train_oj, 
               control = rpart.control(cp = 0))

cpTable <- printcp(tree2)
plotcp(tree2)
```

###  Use cross-validation to determine the tree size and create a plot of the final tree.

```{r}
# minimum cross-validation error
minErr <- which.min(cpTable[,4])
tree3 <- prune(tree2, cp = cpTable[minErr,1])
rpart.plot(tree3)
summary(tree3)

```

When the tree size is `r cpTable[minErr,2]` corresponds to the lowest cross-validation error.

### Using the 1 SE rule

```{r}
tree4 <- prune(tree2, cp = cpTable[cpTable[,4]<cpTable[minErr,4]+cpTable[minErr,5],1][1])
rpart.plot(tree4)
```

The tree is smaller when the tree size obtained using the 1 SE rule.

\newpage

## Part b

### Perform boosting on the training data.

```{r}
ctrl2 <- trainControl(method = "cv",
                     classProbs = TRUE, 
                     summaryFunction = twoClassSummary)

gbmA.grid <- expand.grid(n.trees = c(2000,3000,4000,5000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.0005,0.001,0.002),
                         n.minobsinnode = 1)
set.seed(2)
gbmA.fit <- train(purchase ~ . ,
                  data = train_oj,
                  tuneGrid = gbmA.grid,
                  trControl = ctrl2,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)

ggplot(gbmA.fit, highlight = TRUE)


```


### Report the variable importance.

```{r}
summary(gbmA.fit$finalModel, las = 2, cBars = 16, cex.names = 0.6)
```

The most important variables are loyal_ch and price_diff.

### Test error

```{r}
gbmA.pred <- predict(gbmA.fit, newdata = test_oj)
test.error = mean(gbmA.pred != test_oj$purchase)
test_error_rate = test.error*100
test_error_rate
```

The test error rate is`r test_error_rate`%.

